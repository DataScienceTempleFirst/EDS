{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning and prediction\n",
    "Elements of Data Science   \n",
    "In this laboratory we will use training data to predict outcomes. We will first test these ideas using our Old Faithful data again. Next we will look at data on the iris flower to classify iris' based on sepal width and length. In our culminating activity we will predict molecular acidity using data computed by [Prof. Vince Voelz](http://www.voelzlab.org) in the Temple Chemistry department and a graduate student, Robert Raddi. See their paper: [Stacking Gaussian processes to improve pKa predictions in the SAMPL7 challenge](https://link.springer.com/epdf/10.1007/s10822-021-00411-8?sharing_token=yLV8dMXdxg40M_Ds_2Rhsfe4RwlQNchNByi7wbcMAY6fCl3bMLQiAhJzS2zZw-SwUkz490heLLZu1bPJ8T5LHXo1WvZkp0AJmWzXo71rszl8UaPxjqtqR-oARfxWGrTiCV0rNXy0C7IVzX6yoMYTPv2ZJfnQS-zF1pYvL8ESsUI%3D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Your_name = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning from training data\n",
    "A key concept in machine learning is using a subset of a dataset to train an algorithm to make estimates on a separate set of test data. The quality of the machine learning and algorithm can be assesed based on the accuracy of the predictions made on test data. Many times there are also parameters sometimes termed hyper-parameters which can be optimized through an iterative approach on test or validation data. In practice a dataset is randomly split into training and test sets using sampling. \n",
    "### k nearest neighbor\n",
    "We will examine one machine learning algorithm in the laboratory, k nearest neighbor. Many of the concepts are applicable to the broad range of machine learning algorithms available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import statements\n",
    "# These lines load the tests. \n",
    "from gofer.ok import check\n",
    "\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "from IPython.display import Image\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "# Fix for datascience collections Iterable\n",
    "import collections as collections\n",
    "import collections.abc as abc\n",
    "collections.Iterable = abc.Iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k nearest  neighbor regression\n",
    "We will use the k nearest neighbor algorithm to make predictions of wait time in minutes following an eruption duration ofa given number of minutes (independent variable).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faithful = Table.read_table(\"data/faithful.csv\")\n",
    "faithful.scatter(0, 1, fit_line=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 1* \n",
    "Use the datascience .split(n) Table method to split the dataset into 80% training and 20% test. The argument for .split(n) method,n, needs to be an integer. [See datascience documentation](https://datascience.readthedocs.io/en/master/_autosummary/datascience.tables.Table.split.html#datascience.tables.Table.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainf, testf = ...\n",
    "print(trainf.num_rows, 'training and', testf.num_rows, 'test instances.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q1.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighor concept\n",
    "The training examines the chreacteristics of *k* nearest neighbors to the data point for which a prediction will be made. Nearness is measured using several different [metrics](https://www.nhm.uio.no/english/research/infrastructure/past/help/similarity.html) with Euclidean distance being a common one for numerical attributes.  \n",
    "Euclidean distance:   \n",
    "1-D $$ d(p,q) = \\sqrt{(p-q)^{2}} $$   \n",
    " 2-D $$ d(p,q) = \\sqrt{(p_1-q_1)^{2}+(p_1-q_1)^{2}} $$\n",
    " \n",
    " For multiple points (rows):\n",
    " 2-D $$ d(p,q) = \\sum{{\\sqrt{((p_1-q_1)^{2}+(p_1-q_1)^{2}}}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Try different attribute values in the following 2D Euclidean distance example code below to get a feel for the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code to compute an Euclidean distance between two 2-D points\n",
    "d_p_q = np.sqrt(sum((make_array(2,3)-make_array(4,3))**2))\n",
    "d_p_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get values from Table row as an array as is done in row_distance. Note in the faithful data case we will only consider the duration column in nearest neighbor computation but in examples below we will use a 2-D array of attributes with the iris data and a 10-D array in the chemistry and molecular acidity case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_array = np.array(faithful.row(0))\n",
    "f_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 2* \n",
    "Define a function which is the Euclidean distance between two values. This is where we will compute the distance between two *duration* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(pt1, pt2):\n",
    "    \"\"\"The distance between two points, represented as arrays.\"\"\"\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q2.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rest of the nearest neighbor algorithm\n",
    "Execute these cells to create the complete algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_distance(row1, row2):\n",
    "    \"\"\"The distance between two rows of a table.\"\"\"\n",
    "    return distance(np.array(row1), np.array(row2)) # Need to convert rows into arrays\n",
    "\n",
    "def distances(training, example, output):\n",
    "    \"\"\"Compute the distance from example for each row in training.\"\"\"\n",
    "    dists = []\n",
    "    attributes = training.drop(output)\n",
    "    for row in attributes.rows:\n",
    "        dists.append(row_distance(row, example))\n",
    "    return training.with_column('Distance', dists)\n",
    "\n",
    "def closest(training, example, k, output):\n",
    "    \"\"\"Return a table of the k closest neighbors to example.\"\"\"\n",
    "    return distances(training, example, output).sort('Distance').take(np.arange(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 3*\n",
    "Take an example row from the test data (testf), drop the prediction column and use the closest function to see the top 10 closest points to the target in the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_row = ...\n",
    "k = ... # Number of nearest neighbors\n",
    "closest(...,example_row,...,'wait')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q3.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 4*\n",
    "Predict the value for this row using the defined predict_nn function below and compare to the value reported for wait in the test data. How do they compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nn(example):\n",
    "    \"\"\"Return the majority class among the k nearest neighbors.\"\"\"\n",
    "    k = 10\n",
    "    return np.average(closest(trainf, example, k , 'wait').column('wait'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionf = ...\n",
    "actual = ...\n",
    "print(predictionf,actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> Answer here  </font>\n",
    "***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q4.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 5* Predictions\n",
    "Now we will make predictions for the whole data set using the apply Table method. We will then look at the root mean squared error (RMSE) for the nearest neighbor fit and a scatter plot. Try adjusting the value of k in the predict_nn function to see it's effect on the quality of fit by rerunning these cells. Are the predicted points in a **perfect** straight line, why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testf = testf.with_columns(\"predict\",testf.apply(predict_nn,\"duration\"))\n",
    "nn_test_predictions = testf.column(\"predict\")\n",
    "test_wait = testf.column(\"wait\")\n",
    "rmse_nn = np.mean((test_wait - nn_test_predictions) ** 2) ** 0.5\n",
    "\n",
    "print('Test set RMSE for nearest neighbor regression:', round(rmse_nn,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testf.scatter(\"duration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> Answer here  </font>\n",
    "***  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify iris data with machine learning\n",
    "Next we will take on the problem of classifying iris data into three categories, setosa, versicolor, and virginica. Here we will also learn the basics of the k nearest neighbor algorithm.\n",
    "\n",
    "The first data set we will look at consists of 50 samples from three species of Iris (Iris Setosa, Iris virginica, and Iris versicolor). Four features were measured including the length and the width of the sepals and petals, in centimeters for each observation.\n",
    "<br><center><img src='iris.png' width=150 height=150>Iris stainglass, J.R. Smith</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 15\n",
    "# Load iris data\n",
    "iris = datasets.load_iris()\n",
    "# We only take the first two features. \n",
    "iris_table = Table().with_columns(\"Name\",iris.target,iris.feature_names[0],iris.data[:,0],iris.feature_names[1],iris.data[:,1])\n",
    "iris_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 6*\n",
    "Train and test split the iris_table @ 80% as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_i, test_i = ...\n",
    "print(train_i.num_rows, 'training and', test_i.num_rows, 'test instances.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q6.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 7* \n",
    "With classification we need to use training data to decide how to classify data given a set of attributes, sepal length and sepal width in this case. Create a function which returns the majority classification among three possibilities in \"Name\" coded as 0, 1, 2 (setosa, versicolor, and virginica respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority(topkclasses):\n",
    "    twos = topkclasses.where('Name', are.equal_to(2)).num_rows\n",
    "    ones = ...\n",
    "    zeros = ...\n",
    "    # Now test to see what the majority name for each k class\n",
    "    if ... and ...:\n",
    "        return 2\n",
    "    elif ... and ...:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q7.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(training, new_point, k):\n",
    "    closestk = closest(training, new_point, k,\"Name\")\n",
    "    topkclasses = closestk.select('Name')\n",
    "    return majority(topkclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prediction: \",classify(train_i,example_row,5),\" Actual: \",test_i.select(\"Name\").row(18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train, test_attributes, k):\n",
    "    pred = []\n",
    "    for i in np.arange(test_attributes.num_rows):\n",
    "        pred.append(classify(train,test_attributes.row(i),k))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 8*\n",
    "Make a new table called prediction which includes original columns of test Table but also includes a \"predict\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = ...\n",
    "prediction = test_i.with_columns(\"predict\",...)\n",
    "prediction.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q8.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot decision outcomes for test set\n",
    "#### *Question 9* \n",
    "Use above prediction Table to make a scatter plot of the color coded predictions based on the tweo attributes(use colors=\"predict\" in scatter plot after specifying x and y axis based on attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.drop(\"Name\").scatter(...,...,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fancy plot showing color coded decision boundaries\n",
    "We can make a more informative plot by predicting on a grid of attribute values as shown below. Seaborn is an add-on to the Matplotlib plotting we have been using which provides more control of plotting. Execute (this may take a minute+) and study the below input and resulting output for your information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_colors(iris, y, cmap):\n",
    "    colors = []\n",
    "    cdict = {'setosa':0, 'virginica':2, 'versicolor':1}\n",
    "    for x in iris.target_names[y]:\n",
    "        colors.append(cmap[cdict[x]])\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "h = .1  # step size in the mesh\n",
    "k = 10\n",
    "x_min, x_max = iris.data[:, 0].min() - 1, iris.data[:, 0].max() + 1\n",
    "y_min, y_max = iris.data[:, 1].min() - 1, iris.data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "## Create a grid of predictions in a Table\n",
    "attribute_grid = Table().with_columns(iris.feature_names[0],np.c_[xx.ravel(), yy.ravel()][:,0],iris.feature_names[1],np.c_[xx.ravel(), yy.ravel()][:,1])\n",
    "\n",
    "Z = np.array(predict(train_i,attribute_grid,k))\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['orange', 'cyan', 'cornflowerblue'])\n",
    "cmap_bold = ['darkorange', 'c', 'darkblue']\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot the test points but convert to numpy arrays\n",
    "predictions = prediction.column('predict')\n",
    "attribute1 = prediction.column(1)\n",
    "attribute2 = prediction.column(2)\n",
    "plt.scatter(x=attribute1, y=attribute2, c = make_colors(iris, predictions, cmap_bold), alpha=1.0, edgecolor=\"black\")\n",
    "\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"3-Class classification (k = %i')\"\n",
    "              % (k))\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use scikit learn\n",
    "[Scikit learn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.neighbors) is a standard state of the art machine learning library. For demonstration purposes execute the below commands to classify  and generate a comparable output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = neighbors.KNeighborsClassifier(k) # Initiate the classifier\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data[:,:2], iris.target, random_state=22) #  scikit split\n",
    "# Now fit\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "h = .1  # step size in the mesh\n",
    "x_min, x_max = iris.data[:, 0].min() - 1, iris.data[:, 0].max() + 1\n",
    "y_min, y_max = iris.data[:, 1].min() - 1, iris.data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['orange', 'cyan', 'cornflowerblue'])\n",
    "cmap_bold = ['darkorange', 'c', 'darkblue']\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "y = y_test\n",
    "plt.scatter(x=x_test[:, 0], y=x_test[:, 1], c = make_colors(iris, y, cmap_bold),\n",
    "                    alpha=1.0, edgecolor=\"black\")\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"3-Class classification (k = %i')\"\n",
    "              % (k))\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 10* \n",
    "Comment on the quality of the predictions by \n",
    "1. Your nearest neighjbor algorithm \n",
    "2. scikit learn \n",
    "3. Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Answers here </font>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Molecules and predicting acidity measured by pKa\n",
    "Within the Jupyter notebook we can also analyze molecules and their molecular data using the library  RDKit. RDKit adds the ability to visualize 2D and 3D molecular structures. We can apply many of the data science tools we have learned to molecular data as well. First we will briefly look at acid-base chemistry and how acidity is defined. Next we will use some computed atributes of a large set of molecules to train a k nearest neighbor model to predict acidity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acid-base and pKa background\n",
    "A very brief background on acid - base equilibria demonstrated for glycine. See [OpenStax Chemistry](https://openstax.org/books/chemistry-2e/pages/14-introduction) for details based on interest.\n",
    "<br><center><img src='acid_base_pKa.png' width=900></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDKit\n",
    "RDKit is a specialized library to handle the complexities of molecules within Python. <br><font color='blue'>To utilize the chemistry rdkit in our Jupyter notebook environment the advanced environment will need to be selected. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole #Needed to show molecules\n",
    "from rdkit.Chem.Draw.MolDrawing import MolDrawing, DrawingOptions #Only needed if modifying defaults\n",
    "from rdkit.Chem import rdRGroupDecomposition\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import DataStructs\n",
    "# Options\n",
    "DrawingOptions.bondLineWidth=1.8\n",
    "rd =True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load detailed molecular data for 2000 molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/robraddi/GP-SAMPL7/main/pKaDatabase/OChem/ochem0-2000.csv\"\n",
    "data = Table.read_table(url)\n",
    "data=data.sort('N')\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 11.* Select an amino acid \n",
    " Use the Table above to view data for an amino acid of your selection from the 21 amino acids which are building blocks of protiens. See [web page](https://i.pinimg.com/originals/a2/fd/dd/a2fddd4ad8b9067bfeb0d6f51cf28e71.jpg) for possible choices. Hint: use are.containing within the .where() Table method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino = ...\n",
    "amino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q11.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display molecular structure\n",
    "[SMILES](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) is a shorthand language to describe molecular structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.MolFromSmiles(\"[H]-O-[H]\") #Water\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.MolFromSmiles(\"C-C-O\") #Ethanol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Chem.MolFromSmiles(\"[NH2+]CC(O)=O\") # Glycine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selected amino acid 2D molecular structure\n",
    "Try it out for fun! Use the same above syntax and the SMILES string from your above Table to display a 2D amino acid structurefrom your selection. Even if there is no rdkit, try your hand at the SMILES molecular description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smile_struct = '...'\n",
    "\n",
    "Chem.MolFromSmiles(smile_struct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to create a grid of molecular images with labels\n",
    "Execute and study the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mols = [Chem.MolFromSmiles(x) for x in amino.column(\"SMILES\") if x is not None]\n",
    "mols\n",
    "name = amino.column(\"NAME\")\n",
    "\n",
    "for i,m in enumerate(mols):\n",
    "    m.SetProp(\"Name\",name[i])\n",
    "\n",
    "p = Draw.MolsToGridImage( [mols[x] for x in range(0,3)] , legends=[x.GetProp(\"Name\") for x in mols],molsPerRow=3,subImgSize=(300,250), useSVG=True )\n",
    "p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pandas to add 2D structures to dataframe\n",
    "We can convert our Table to pandas then use the RDKit AddMoleculeColumnToFrame method to add structures. One row has an anomolous nitrogen atom, N, so don't be alarmed by the error presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = data.to_df() # Convert Table to pandas dataframe\n",
    "PandasTools.AddMoleculeColumnToFrame(df,smilesCol='SMILES',molCol='Molecule')\n",
    "col = df.pop(\"Molecule\")\n",
    "df.insert(0, col.name, col) # Move structure to first column\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pKa data examination\n",
    "Now we will look at a data set derived from the above data but with computed molecular attributes for our machine learning. This data set is computed and described by  [Prof. Vince Voelz](http://www.voelzlab.org) in the Temple Chemistry department and a graduate student, Robert Raddi. See their paper: [Stacking Gaussian processes to improve pKa predictions in the SAMPL7 challenge](https://link.springer.com/epdf/10.1007/s10822-021-00411-8?sharing_token=yLV8dMXdxg40M_Ds_2Rhsfe4RwlQNchNByi7wbcMAY6fCl3bMLQiAhJzS2zZw-SwUkz490heLLZu1bPJ8T5LHXo1WvZkp0AJmWzXo71rszl8UaPxjqtqR-oARfxWGrTiCV0rNXy0C7IVzX6yoMYTPv2ZJfnQS-zF1pYvL8ESsUI%3D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.read_csv(\"data/pKaDatabase.csv\")  #csv format for data\n",
    "db_table = Table().from_df(db) # Datascience Table from pandas dataframe\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glycine=db_table.where(\"protonated microstate ID\",are.containing(\"acetic acid\"))\n",
    "\n",
    "mols = [Chem.MolFromSmiles(x) for x in glycine.column(\"protonated microstate smiles\") if x is not None]\n",
    "\n",
    "name = glycine.column(\"pKa\")\n",
    "\n",
    "for i,m in enumerate(mols):\n",
    "    m.SetProp(\"Name\",\"pKa: \"+str(name[i]))\n",
    "\n",
    "p = Draw.MolsToGridImage( [mols[x] for x in range(0,3)] , legends=[x.GetProp(\"Name\") for x in mols],molsPerRow=2,subImgSize=(300,250), useSVG=True )\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### protonated microstate smiles\n",
    "Place the pKa which we will predict in the first column. Use SMILES format to display structures if rdkit is available. Execute below cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PandasTools.AddMoleculeColumnToFrame(db,smilesCol='protonated microstate smiles',molCol='Molecule',includeFingerprints=True)\n",
    "PandasTools.AddMoleculeColumnToFrame(db, smilesCol='protonated microstate smiles', molCol='protonated molecule')\n",
    "PandasTools.AddMoleculeColumnToFrame(db, smilesCol='deprotonated microstate smiles', molCol='deprotonated molecule')\n",
    "col = db.pop('protonated molecule')\n",
    "db.insert(0, col.name, col)\n",
    "col = db.pop('deprotonated molecule')\n",
    "db.insert(1, col.name, col)\n",
    "col = db.pop(\"pKa\")\n",
    "db.insert(0, col.name, col)\n",
    "db=db.sort_values(by='pKa',ascending=False)\n",
    "db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[db['protonated microstate ID'].str.contains('glycine', regex=False)] # Glycine containing molecular names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine a few acidity and molecular weight distribution\n",
    "The below code will generate histograms for acidity as measured by pKa and molar molecular weight measured in grams per mole. Execute code and examine output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(2,2,1)\n",
    "ax1 = plt.subplot(2,2,2)\n",
    "db.sort_values('Weight', ascending=True)\n",
    "ax = db[\"Weight\"].plot.hist(rot=0, figsize=(14, 4), bins=25, edgecolor='black', linewidth=1.2, ax=ax)\n",
    "ax.set_xlabel(\"molecular weight\", size=16)\n",
    "ax.set_ylabel(\"\", size=12)\n",
    "ax.axvline(x=db['Weight'].mean(), linewidth=4, color='r')\n",
    "\n",
    "ax1 = db[\"pKa\"].plot.hist(rot=0, figsize=(14, 4), bins=25, edgecolor='black', linewidth=1.2, ax=ax1)#, subplots=True, layout=(2,2))\n",
    "ax1.set_xlabel(r\"$pK_{a}$\", size=16)\n",
    "ax1.set_ylabel(\"\", size=12)\n",
    "ax1.axvline(x=4, linewidth=4, color='r')\n",
    "ax1.axvline(x=9, linewidth=4, color='r')\n",
    "fig = ax1.get_figure()\n",
    "fig.savefig(\"MW_dist.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at pKa and molecular attribute relationships\n",
    "Here we will plot some of the attributes to see if there is a relationship between their values and the pKa we are trying to predict. Execute these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.plot.scatter(\"Weight\",\"pKa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.plot.scatter(\"AM1BCC partial charge (prot. atom)\",\"pKa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.plot.scatter(\"Bond Order\",\"pKa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Nearest Neighbor\n",
    "Let's restrict our consideration to acids with 0 < pKa < 7. The reason may be evident from the distribution in the histogram of pKa's above with two peaks, one around 4 and another at 8. The negative pKa's are outliers which also will be difficult to predict. For machine learning we will also drop the 2D molecular structures (if rdkit is present)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblow = db[db[\"pKa\"].values<7]\n",
    "dblow = dblow[dblow[\"pKa\"].values>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db2=dblow.drop(['protonated molecule','deprotonated molecule'], axis = 1)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecular = Table().from_df(db2) # Now back to Table\n",
    "molecular.labels # Look at labels to select correct attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection of attributes/features for training and prediction\n",
    "We need too select the features that we will use in the training. These will include the charges computed for key atoms adjacent to the acidic proton (H+) in columns (6-11) using the AM1BCC method, âˆ†G_solv (kJ/mol) (prot-deprot) in column 24,solvent accessible surface area (SASA) in column 25, bond order in column 27, and Change in Enthalpy (kJ/mol) (prot-deprot) in column 28. These are the 10 features we will use. We also keep the labels and SMILES as well as the pKa we will train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecular=molecular.select(0,2,3,4,5,6,7,8,9,10,11,24,25,27,28)\n",
    "molecular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, test split\n",
    "####  *Question 12* \n",
    "Split the molecular Table into train and test data using 80% for training and remembering that the split must be an integer using int() function. Again we will select certain rowsas attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = molecular.split(...)\n",
    "print(train.num_rows, 'training and', test.num_rows, 'test instances.')\n",
    "train_nn = train\n",
    "test_nn = test\n",
    "train_nn.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q12.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our k nearest neighbors code\n",
    "\n",
    "Remember our the k nearest neighbor code from above which wewill again use here.\n",
    "<code>\n",
    "    def row_distance(row1, row2):\n",
    "    \"\"\"The distance between two rows of a table.\"\"\"\n",
    "    return distance(np.array(row1), np.array(row2))\n",
    "\n",
    "def distances(training, example, output):\n",
    "    \"\"\"Compute the distance from example for each row in training.\"\"\"\n",
    "    dists = []\n",
    "    attributes = training.drop(output)\n",
    "    for row in attributes.rows:\n",
    "        dists.append(row_distance(row, example))\n",
    "    return training.with_column('Distance', dists)\n",
    "\n",
    "def closest(training, example, k, output):\n",
    "    \"\"\"Return a table of the k closest neighbors to example.\"\"\"\n",
    "    return distances(training, example, output).sort('Distance').take(np.arange(k))\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test algorithm\n",
    "Execute these cells to define the predict_nn function for pKa, pick an example row, predict and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nn(example):\n",
    "    \"\"\"Return the majority class among the k nearest neighbors.\"\"\"\n",
    "    k = 10\n",
    "    return np.average(closest(train_nn.drop(1,2,3,4), example, k, 'pKa').column('pKa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at closest in training set to test row. \n",
    "closest(train_nn.drop(1,2,3,4), test_nn.drop(0,1,2,3,4).row(100), k, 'pKa').select('pKa','Distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we use training data in both cases we get exact match and no training, not machine learning but matching!\n",
    "closest(train_nn.drop(1,2,3,4), train_nn.drop(0,1,2,3,4).row(100), k, 'pKa').select('pKa','Distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of experimental acidity to be predicted\n",
    "#### *Question*  \n",
    "Make a histogram of acidity measured by pKa in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 13* Prediction time\n",
    "Now predict the pKa of the 10 molecule in the test_nn dataset using predict. We need to drop the experimental pKa and descriptors in the first 4 columns to create and example_nn_row with the attributes for the k nearest neighbor. Discuss the quality of the fit and the name of the name of the molecule from column 1. Repeat for two more rows and discuss the prediction quality. Keep in mind that the prediction of pKa is a very challenging task for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_nn_row = ...\n",
    "print('Experimental pKa:', test_nn.column('pKa').item(100))\n",
    "print('Predicted pKa using nearest neighbors:', round(predict_nn(example_nn_row),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q13.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's plot knn prediction success\n",
    "Execute the next three cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_pKa = make_array()\n",
    "predict_pKA = make_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a while!\n",
    "for i in np.arange(test_nn.num_rows):\n",
    "    exp_pKa = np.append(exp_pKa,test_nn.column('pKa').item(i))\n",
    "    example_nn_row = test_nn.drop(0,1,2,3,4).row(i)\n",
    "    predict_pKA = np.append(predict_pKA,predict_nn(example_nn_row) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(exp_pKa,predict_pKA)\n",
    "#calculate equation for regression line\n",
    "z = np.polyfit(exp_pKa,predict_pKA, 1)\n",
    "p = np.poly1d(z)\n",
    "#add trendline to plot\n",
    "plt.plot(exp_pKa, p(exp_pKa),'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions on our k nearest neighbor model\n",
    "#### *Question 14* \n",
    "Evaluate the overall quality of our machine learning prediction based on the above plot and your 3 predictions above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Your discussion </font>\n",
    "***   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now demonstrate knn from scikit learn\n",
    "scikit learn is a standard and powerful machine learning library. Below is a demonstration for your information of the same machine learning task using scikit learn. Execute the below cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=15, weights='distance',p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = make_array()\n",
    "attributes = train_nn.drop('pKa',1,2,3,4)\n",
    "for i in np.arange(attributes.num_rows):\n",
    "    X=np.append(X,np.array(attributes.row(i)))\n",
    "X=X.reshape(attributes.num_rows,len(attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train_nn.column('pKa')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now test attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = test_nn.drop('pKa',1,2,3,4)\n",
    "Xtest = make_array()\n",
    "for i in np.arange(attributes.num_rows):\n",
    "    Xtest=np.append(Xtest,np.array(attributes.row(i)))\n",
    "Xtest=Xtest.reshape(attributes.num_rows,len(attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest=test_nn.column('pKa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = knn.predict(Xtest)\n",
    "predict_nn = test_nn.with_columns(\"pKa predict\",y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ytest,y_predicted)\n",
    "#calculate equation for regression line\n",
    "z = np.polyfit(ytest,y_predicted, 1)\n",
    "p = np.poly1d(z)\n",
    "# Label with equation\n",
    "print(p)\n",
    "#add trendline to plot\n",
    "plt.plot(ytest, p(ytest),'red',label=\"{}\".format(p))\n",
    "plt.legend(fontsize=\"small\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return the coefficient of determination of the prediction.\n",
    "\n",
    "The coefficient of determination $R^2$ is defined as \n",
    " $$ (1-\\frac{u}{v}) $$ u is the residual sum of squares ((y_true - y_pred)** 2).sum() and v\n",
    "is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \n",
    "$R^2 = 0.0 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(Xtest, ytest) # knn score 0-1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final fancy plotting of select molecules\n",
    "#### *Question 15* \n",
    "Use a part of a molecular name to see if it is included in the test data and then execute the code to examine structures. Structures will be default structures if rdkit is not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecular_name = ...\n",
    "predict_nn.where(\"protonated microstate ID\",are.containing(molecular_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q15.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "glycine=predict_nn.where(\"protonated microstate ID\",are.containing(molecular_name))\n",
    "mols = [Chem.MolFromSmiles(x) for x in glycine.column(\"protonated microstate smiles\") if x is not None]\n",
    "molde = [Chem.MolFromSmiles(x) for x in glycine.column(\"deprotonated microstate smiles\") if x is not None]\n",
    "mol = [None] * 2 * glycine.num_rows\n",
    "mol[0::2]=mols\n",
    "mol[1::2]=molde\n",
    "label = [None] * 2 * glycine.num_rows\n",
    "lpred = [None] * 2 * glycine.num_rows\n",
    "exp = glycine.column(\"pKa\")\n",
    "pred = glycine.column(\"pKa predict\")\n",
    "label[0::2] = exp\n",
    "label[1::2] = exp\n",
    "lpred[0::2] = pred\n",
    "lpred[1::2] = pred\n",
    "for i,m in enumerate(mol):\n",
    "    m.SetProp(\"Name\",\"pKa: \"+str(np.round(label[i],2))+\"  knn: \"+str(np.round(lpred[i],2)))\n",
    "\n",
    "p = Draw.MolsToGridImage( [mol[x] for x in range(0,(2 * glycine.num_rows))] , legends=[x.GetProp(\"Name\") for x in mol],molsPerRow=2,subImgSize=(300,250))\n",
    "p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All finished...\n",
    "Run checks and submit .html and .ipynb files after downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import glob\n",
    "from gofer.ok import check\n",
    "correct = 0\n",
    "checks = [1,2,3,4,6,7,8,11,12,13,15]\n",
    "total = len(checks)\n",
    "for x in checks:\n",
    "    print('Testing question {}: '.format(str(x)))\n",
    "    g = check('tests/q{}.py'.format(str(x)))\n",
    "    if g.grade == 1.0:\n",
    "        print(\"Passed\")\n",
    "        correct += 1\n",
    "    else:\n",
    "        print('Failed')\n",
    "        display(g)\n",
    "\n",
    "print('Grade:  {}'.format(str(correct/total)))\n",
    "print(\"Nice work \",Your_name)\n",
    "import time;\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print(\"Submitted @ \", localtime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
