{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 6: Simulation\n",
    "\n",
    "*Elements of Data Science* <br>\n",
    "Welcome to Module 2 and lab 6! This week, we will go over conditionals and iteration, and introduce the concept of randomness. All of this material is covered in [Chapter 9](https://inferentialthinking.com/chapters/09/Randomness.html) and [Chapter 10](https://inferentialthinking.com/chapters/10/Sampling_and_Empirical_Distributions.html) of the online <i>Inferential Thinking</i> textbook. \n",
    "\n",
    "First, set up the tests and imports by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import statements\n",
    "from gofer.ok import check\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "# Fix for datascience plots\n",
    "import collections as collections\n",
    "import collections.abc as abc\n",
    "collections.Iterable = abc.Iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Dungeons and Dragons and Sampling\n",
    "In the game Dungeons & Dragons, each player plays the role of a fantasy character.\n",
    "A player performs actions by rolling a 20-sided die, adding a \"modifier\" number to the roll, and comparing the total to a threshold for success. The modifier depends on her character's competence in performing the action.\n",
    "For example, suppose Alice's character, a barbarian warrior named Roga, is trying to knock down a heavy door. She rolls a 20-sided die, adds a modifier of 11 to the result (because her character is good at knocking down doors), and *succeeds if the total is greater than 15*.<br> A Medium posting discusses probability in the context of Dungeons and Dragons https://towardsdatascience.com/understanding-probability-theory-with-dungeons-and-dragons-a36bc69aec88 <br><br><img src= data/DnD.JPG height=\"200\"><br>\n",
    "**Question 1.1** Write code that simulates that procedure. Compute three values: the result of Alice's roll (roll_result), the result of her roll plus Roga's modifier (modified_result), and a boolean value indicating whether the action succeeded (action_succeeded). Do not fill in any of the results manually; the entire simulation should happen in code.\n",
    "Hint: A roll of a 20-sided die is a number chosen uniformly from the array make_array(1, 2, 3, 4, ..., 20). So a roll of a 20-sided die plus 11 is a number chosen uniformly from that array, plus 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_rolls = ...\n",
    "roll_result = ...\n",
    "modified_result = ...\n",
    "action_succeeded = ...\n",
    "\n",
    "# The next line just prints out your results in a nice way\n",
    "# once you're done.  You can delete it if you want.\n",
    "print(\"On a modified roll of {:d}, Alice's action {}.\".format(modified_result, \"succeeded\" if action_succeeded else \"failed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q1.1.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2** Run your cell 7 times to manually estimate the chance that Alice succeeds at this action. (Don't use math or an extended simulation.). Your answer should be a fraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rough_success_chance = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q1.2.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we don't know that Roga has a modifier of 11 for this action.  Instead, we observe the modified roll (that is, the die roll plus the modifier of 11) from each of 7 of her attempts to knock down doors.  We would like to estimate her modifier from these 7 numbers.<br>\n",
    "\n",
    "**Question 1.3** Write a Python function called `simulate_observations`.  It should take two arguments, the modifier and num_oobservations, and it should return an array of num_observations.  Each of the numbers should be the modified roll from one simulation.  **Then**, call your function once to compute an array of 7 simulated modified rolls.  Name that array `observations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifier = 11\n",
    "num_observations = 7\n",
    "\n",
    "def simulate_observations(modifier, num_observations):\n",
    "    \"\"\"Produces an array of 7 simulated modified die rolls\"\"\"\n",
    "    ...\n",
    "\n",
    "observations = ...\n",
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q1.3.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4** Draw a histogram to display the *probability distribution* of the modified rolls we might see.  Check with a neighbor or a CA to make sure you have the right histogram. Carry this out again using 100 rolls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We suggest using these bins.\n",
    "roll_bins = np.arange(1, modifier+2+20, 1)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the modifier\n",
    "Now let's imagine we don't know the modifier and try to estimate it from observations.\n",
    "One straightforward (but clearly suboptimal) way to do that is to find the smallest total roll, since the smallest roll on a 20-sided die is 1, which is roughly 0. Use a random number for <i>modifier</i> to start and keep this value through the next questions. We will also generate 100 rolls based on the below unknown modifier. <br>\n",
    "**Question 1.5** Using that method, estimate modifier from observations. Name your estimate min_estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifier = np.random.randint(1,20) # Generates a random integer modifier from 1 to 20 inclusive\n",
    "simulate_observations(modifier, num_observations)\n",
    "...\n",
    "min_estimate = ...\n",
    "min_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q1.5.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate the modifier based on the mean of observations.\n",
    "**Question 1.6** Figure out a good estimate based on that quantity. Then, write a function named mean_based_estimator that computes your estimate. It should take an array of modified rolls (like the array observations) as its argument and return an estimate of modifier based on those numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_based_estimator(nums):\n",
    "    \"\"\"Estimate the roll modifier based on observed modified rolls in the array nums.\"\"\"\n",
    "    ...\n",
    "\n",
    "# Here is an example call to your function.  It computes an estimate\n",
    "# of the modifier from our  observations.\n",
    "mean_based_estimate = mean_based_estimator(observations)\n",
    "mean_based_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q1.6.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.7** Construct a histogram and compare to above estimates, are they consistent?\n",
    "What is your best estimate of the random modiifer based on the above, without examining the value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(..., bins = ...) # Use to plot histogram of an array of 100 modified rolls\n",
    "estimated_modifier = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q1.7.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sampling and GC content of DNA sequence\n",
    "DNA within a cell contains codes or sequences for the ultimate synthesis of proteins. In DNA is made up of four types of nucleotides, guanine (G), cytosine (C), adenine (A), and thymine (T) connected in an oredered sequence. These nucleotides on a single strand pair with complimentary nucleotides on a second strand, G pairs with C and A with T. Regions of DNA code for RNA which ultimately directs protein synthesis and these segments are known as genes and these segments often have higher GC content. Hear we will sample 10 nuclotide segments of a DNA sequence and determine the GC content of these DNA segments. See [DNA sequnce basics](http://data-science-sequencing.github.io/Win2018/assets/lecture2/lecture2_2018.pdf) and [GC Content details](https://geneticeducation.co.in/what-is-the-importance-of-gc-content/). \n",
    "##### Our goal is to sample portions (10 nucelotides) of the sequence and determine the relative content of guanine (G) and cytosine (C) to adenine (A) and thymine (T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNA sequence we will examine, a string\n",
    "seq = \"CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGATGAGACCGTGGAATAAACGATCGAGTG \\\n",
    "AATCCGGAGGACCGGTGTACTCAGCTCACCGGGGGCATTGCTCCCGTGGTGACCCTGATTTGTTGTTGGG \\\n",
    "CCGCCTCGGGAGCGTCCATGGCGGGTTTGAACCTCTAGCCCGGCGCAGTTTGGGCGCCAAGCCATATGAA \\\n",
    "AGCATCACCGGCGAATGGCATTGTCTTCCCCAAAACCCGGAGCGGCGGCGTGCTGTCGCGTGCCCAATGA \\\n",
    "ATTTTGATGACTCTCGCAAACGGGAATCTTGGCTCTTTGCATCGGATGGAAGGACGCAGCGAAATGCGAT \\\n",
    "AAGTGGTGTGAATTGCAAGATCCCGTGAACCATCGAGTCTTTTGAACGCAAGTTGCGCCCGAGGCCATCA \\\n",
    "GGCTAAGGGCACGCCTGCTTGGGCGTCGCGCTTCGTCTCTCTCCTGCCAATGCTTGCCCGGCATACAGCC \\\n",
    "AGGCCGGCGTGGTGCGGATGTGAAAGATTGGCCCCTTGTGCCTAGGTGCGGCGGGTCCAAGAGCTGGTGT \\\n",
    "TTTGATGGCCCGGAACCCGGCAAGAGGTGGACGGATGCTGGCAGCAGCTGCCGTGCGAATCCCCCATGTT \\\n",
    "GTCGTGCTTGTCGGACAGGCAGGAGAACCCTTCCGAACCCCAATGGAGGGCGGTTGACCGCCATTCGGAT \\\n",
    "GTGACCCCAGGTCAGGCGGGGGCACCCGCTGAGTTTACGC\" # LCBO-Prolactin precursor-Bovine\n",
    "seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1A** Run the first two code cells below to see how substrings are extracted and how a character can be counted within a substring. Use the same strategy to determine GC content as fraction of the total in the first 10 nucleotides in the larger sequence above, `seq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example A\n",
    "samplesize = 4\n",
    "# Use this short sequence in this example\n",
    "seq0 = 'GTGAAAGATT'\n",
    "# How to get a substring\n",
    "seq0[0:samplesize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example B\n",
    "# How to count the number of times 'A' appears in sequence\n",
    "seq0[0:samplesize].count('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCcount = seq[0:10].count('G') + seq[...]...\n",
    "GCfraction = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lists\n",
    "Below we assemble a list and append an additional entry, 0.7. A useful strategy in creating your function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = []\n",
    "gc.append(0.8)\n",
    "gc.append(0.7)\n",
    "gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill a list with 30 random G, C, T, A nucleotides \n",
    "use iteration and `np.random.choice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sim_seq = []\n",
    "nucleo = ['G','C','T','A']\n",
    "for i in np.arange(...):\n",
    "    my_sim_seq.append(np. ...)\n",
    "\n",
    "print(my_sim_seq)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1B** We will define a function, `calcGC` to do the repetitive work of computing GC content fraction for each segment (samplesize) and return a list with the fraction GC for each `samplesize` segment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcGC(seq, samplesize):\n",
    "    gc = []\n",
    "    for i in range(len(seq)-samplesize):\n",
    "    ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q2.1.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2**\n",
    "Apply this function to our sequence above <i>seq</i> with a samplesize of 10. What is the maximum, minimum, mean, and median? (Hint: the max of a list can be obtained with the max(results) and we can use np.mean(results)). Plot the results by using plt.plot(results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesize = ...\n",
    "results = ...\n",
    "maximum = ...\n",
    "minimum = ...\n",
    "median = ...\n",
    "mean = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q2.2.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3** Now apply this function to our sequence above <i>seq</i> with a different, larger samplesize (>30) of your choosing and plot. What do you observed with the different sampling? What is the maximum, minimum, mean, and median? (Hint: the max of a list can be obtained with the max(results) and we can use np.median(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "<font color='green'> Discuss your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Wordle and sampling\n",
    "Inspired by Medium post: https://ericlani.medium.com/determining-the-best-first-wordle-word-to-guess-using-data-b93b975a6294\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Letter frequency in sampled texts\n",
    "We will begin our study by trying to understand the frequency of certain letters by sampling texts.  We will again use Charles Darwin's book on the Origin of Species to examine the frequency of letters in this text. To do this we will need to write a function which goes through all the words and determines the counts of letters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darwin_string = open('data/darwin_origin_species.txt', encoding='utf-8').read()\n",
    "darwin_words = np.array(darwin_string.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1** Define a function to determine letter frequency in text with words split in an array as in above <i>darwin_words</i> array and return a Table with letters and their count. We will use a nice trick with a Python disctionary as already encoded below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_freq(words):\n",
    "    for ...:\n",
    "        for ...:\n",
    "            l = l.lower()\n",
    "            if l.isalpha(): # avoid punctuation\n",
    "                f[i] = f.get(i,0) + 1 # Using Python dictionary\n",
    "    return Table().with_columns('letters',list(f.keys()),'count',list(f.values()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q3.1.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2** Apply the function to the <i>darwin_string</i> and examine the output. How many total letters in the text (Hint: use np.sum(freq.column('count')))? Now compute a new column, <i>frequency</i> which contains the fraction of each letter. What are the two most frequent letters in this sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = letter_freq(darwin_words).sort(\"letters\")\n",
    "\n",
    "total_letters = ... # How many letters\n",
    "\n",
    "freq = freq.with_columns(...).sort(\"frequency\",descending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q3.2.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Five letter words\n",
    "**Question 3.3** Now look at a list of 5 letter words assembled by Professor Emeritas Donald Knuth of Stanford. Use your function to determine the letter frequency and compare to above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen # Needed to read from internet\n",
    "\n",
    "url = \"https://www-cs-faculty.stanford.edu/~knuth/sgb-words.txt\"\n",
    "knuth5_string=urlopen(url).read().decode('utf-8') \n",
    "knuth_words = np.array(knuth5_string.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply your function and compute letter frequencies\n",
    "freq = ...\n",
    "\n",
    "freq = freq.with_columns(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q3.3.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with Oxford Dictionary\n",
    "Based on analysis of Oxford dictionary these are the letter frequencies from the dictionary. Compare the three, in the markdown below, what are the similarities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"data/Oxford_Letter_frequency.csv\"\n",
    "letters = Table().read_table(url, header=None, names=[\"letters\",\"frequency\",\"count\"])\n",
    "letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparsion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4** Let's look at 5-letter words and the frequency of each letter and compare with Oxford case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordle itself\n",
    "The New York Times hosts [Wordle](https://www.nytimes.com/games/wordle/index.html) where a 5 letter word (Wordle) is determined in six or fewer tries using clues about letters contained and letter position. We will use our new knowledge of letter frequency and Knuth's 5 letter words to come up with best letters and words to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload Knuth's words in more convenient pandas format\n",
    "url = \"https://www-cs-faculty.stanford.edu/~knuth/sgb-words.txt\"\n",
    "# Better to read with pandas\n",
    "import pandas as pd\n",
    "words_df = pd.read_csv(url, header=None, names=[\"Words\",\"value\",\"letters\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load our letter frequency, <i>freq</i>, data table from a chosen text and convert to pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_df = freq.to_df() # Select table from each text above\n",
    "letters_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5** Devise a plan to use the collection of letter frequencies and Knuth's five letter words to order the best words to guess for Wordle? Higher letter frequency means more words with the given letter. Describe plan in text markdown only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Magic\" Wordle computation\n",
    "Takes a while, be patient.\n",
    "Can you interpret how this code is sorting Knuth's words based on our letter frequencies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in words_df.iterrows():\n",
    "    prob = 0\n",
    "    letter_set = set()\n",
    "    for ele in row['Words']:\n",
    "        letter_set.add(ele)\n",
    "        temp_df = letters_df[letters_df[\"frequency\"].where(letters_df[\"letters\"] == ele).notnull()]\n",
    "        temp_df\n",
    "        prob += temp_df[\"frequency\"].iloc[0]\n",
    "        words_df.loc[index, [\"value\"]] = prob\n",
    "        words_df.loc[index, [\"letters\"]] = len(letter_set)\n",
    "        \n",
    "words_df       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four letter words are included now we will select only five letter words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.where(words_df[\"letters\"]==5.0).sort_values(by='value',ascending=False).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6**\n",
    "#### Compare top word given based on Darwin's text, Knuth's letter frequency, and the Oxford Dictionary.\n",
    "\n",
    "Top words for Wordle:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete and tally your score.\n",
    "Submit .html and .ipynb of completed laboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import glob\n",
    "from gofer.ok import check\n",
    "correct = 0\n",
    "total = 11\n",
    "checks = ['1.1','1.2', '1.3', '1.5', '1.6', '1.7', '2.1', '2.2', '3.1', '3.2','3.3']\n",
    "for x in checks:\n",
    "    print('Testing question {}: '.format(x))\n",
    "    g = check('tests/q{}.py'.format(x))\n",
    "    if g.grade == 1.0:\n",
    "        print(\"Passed\")\n",
    "        correct += 1\n",
    "    else:\n",
    "        print('Failed')\n",
    "        display(g)\n",
    "\n",
    "print('Grade:  {}'.format(str(correct/total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name,\" Great work!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
